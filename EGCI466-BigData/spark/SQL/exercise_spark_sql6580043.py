# -*- coding: utf-8 -*-
"""Exercise Spark SQL6580043

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MF-A9j-r2MC-bFhu9rXfpMG9X8UpDwOE
"""

# Installing required packages
!pip install pyspark
!pip install findspark

import findspark
findspark.init()

# PySpark is the Spark API for Python. In this lab, we use PySpark to initialize the spark context.
from pyspark import SparkContext, SparkConf
from pyspark.sql import SparkSession

# Creating a spark context class
sc = SparkContext()

spark = SparkSession \
    .builder \
    .getOrCreate()

dataframe = spark.read.csv("student.csv",header="true")

"""# **Exercise 1**:** Explore the data using DataFrame** functions and SparkSQL




In this section, we explore the datasets using functions both from dataframes as well as corresponding SQL queries using sparksql. Note the different ways to achieve the same task!# New Section
"""

dataframe.show()

dataframe = dataframe.drop(*dataframe.columns[-10:])

df = dataframe.withColumnRenamed("_c3","class")

#drop No.. columns
df = df.drop("No.")

df = df.dropDuplicates()
df.show()

from pyspark.sql.functions import udf
def UpperCase(str):
  return str.upper()

upperCaseUDF=udf(lambda z : UpperCase(z))

df.withColumn("Name",upperCaseUDF("Name")).show()

from pyspark.sql.functions import avg
df = df.withColumn("GPA",df["GPA"].cast("double"))
df = df.fillna((dft.select(avg(dft["GPA"]))).collect()[0][0])
df.show()

from pyspark.sql.functions import udf
def cal_grad_year(ID):
  year = int(ID[0:2])
  year += 2500-543+5 # 65=>2565, convert back to AD and plus graduation
  return year
grad_year_udf=udf(lambda x : cal_grad_year(x))

df=df.withColumn("Graduation Year",grad_year_udf("StudentID"))
df.show()

df.select("StudentID","Name","GPA","Graduation year").show()

#sc.stop()